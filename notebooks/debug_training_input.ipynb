{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug Training Input: Verify Thinking Tags Are Preserved\n",
    "\n",
    "This notebook shows exactly what text/tokens go into the model during training.\n",
    "Use this to verify the fix for the thinking tags bug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from transformers import Qwen3OmniMoeProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processor loaded!\n"
     ]
    }
   ],
   "source": [
    "# Load processor\n",
    "processor = Qwen3OmniMoeProcessor.from_pretrained('Qwen/Qwen3-Omni-30B-A3B-Thinking')\n",
    "print(\"Processor loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Bug: Original Approach (Thinking Stripped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RAW RESPONSE (what we want to train on):\n",
      "============================================================\n",
      "<think>\n",
      "I hear a bird chirping. The sound has a melodic, high-pitched quality typical of songbirds.\n",
      "</think>\n",
      "\n",
      "ANSWER: Bird\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Sample response with thinking\n",
    "response = \"<think>\\nI hear a bird chirping. The sound has a melodic, high-pitched quality typical of songbirds.\\n</think>\\n\\nANSWER: Bird\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"RAW RESPONSE (what we want to train on):\")\n",
    "print(\"=\" * 60)\n",
    "print(response)\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BROKEN: What model was trained on (thinking STRIPPED!):\n",
      "============================================================\n",
      "<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "<|audio_start|><|audio_pad|><|audio_end|>What sound is this?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "ANSWER: Bird<|im_end|>\n",
      "\n",
      "============================================================\n",
      "\n",
      ">>> PROBLEM: <think> tags are GONE!\n"
     ]
    }
   ],
   "source": [
    "# BROKEN: Original approach - include assistant in conversation\n",
    "conversation_broken = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": [{\"type\": \"text\", \"text\": \"You are a helpful assistant.\"}],\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"audio\", \"audio\": \"/path/to/audio.wav\"},\n",
    "            {\"type\": \"text\", \"text\": \"What sound is this?\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [{\"type\": \"text\", \"text\": response}],\n",
    "    },\n",
    "]\n",
    "\n",
    "text_broken = processor.apply_chat_template(\n",
    "    conversation_broken, tokenize=False, add_generation_prompt=False\n",
    ")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"BROKEN: What model was trained on (thinking STRIPPED!):\")\n",
    "print(\"=\" * 60)\n",
    "print(text_broken)\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n>>> PROBLEM: <think> tags are GONE!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Fix: New Approach (Thinking Preserved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FIXED: What model will now train on (thinking PRESERVED!):\n",
      "============================================================\n",
      "<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "<|audio_start|><|audio_pad|><|audio_end|>What sound is this?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>\n",
      "I hear a bird chirping. The sound has a melodic, high-pitched quality typical of songbirds.\n",
      "</think>\n",
      "\n",
      "ANSWER: Bird<|im_end|>\n",
      "\n",
      "============================================================\n",
      "\n",
      ">>> SUCCESS: <think> tags are preserved!\n"
     ]
    }
   ],
   "source": [
    "# FIXED: Only include system + user, manually append assistant\n",
    "conversation_without_assistant = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": [{\"type\": \"text\", \"text\": \"You are a helpful assistant.\"}],\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"audio\", \"audio\": \"/path/to/audio.wav\"},\n",
    "            {\"type\": \"text\", \"text\": \"What sound is this?\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "# Apply template with add_generation_prompt=True\n",
    "text_fixed = processor.apply_chat_template(\n",
    "    conversation_without_assistant, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "# Manually append assistant response\n",
    "text_fixed = text_fixed + response + \"<|im_end|>\\n\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"FIXED: What model will now train on (thinking PRESERVED!):\")\n",
    "print(\"=\" * 60)\n",
    "print(text_fixed)\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n>>> SUCCESS: <think> tags are preserved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Side-by-Side Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPARISON:\n",
      "================================================================================\n",
      "\n",
      "BROKEN (original):\n",
      "----------------------------------------\n",
      "<|im_start|>assistant\n",
      "ANSWER: Bird<|im_end|>\n",
      "\n",
      "\n",
      "FIXED (new):\n",
      "----------------------------------------\n",
      "<|im_start|>assistant\n",
      "<think>\n",
      "I hear a bird chirping. The sound has a melodic, high-pitched quality typical of songbirds.\n",
      "</think>\n",
      "\n",
      "ANSWER: Bird<|im_end|>\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Has <think> tags?\n",
      "  BROKEN: False\n",
      "  FIXED:  True\n"
     ]
    }
   ],
   "source": [
    "print(\"COMPARISON:\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nBROKEN (original):\")\n",
    "print(\"-\" * 40)\n",
    "# Just show assistant part\n",
    "broken_assistant = text_broken.split(\"<|im_start|>assistant\")[1] if \"<|im_start|>assistant\" in text_broken else \"N/A\"\n",
    "print(f\"<|im_start|>assistant{broken_assistant}\")\n",
    "\n",
    "print(\"\\nFIXED (new):\")\n",
    "print(\"-\" * 40)\n",
    "fixed_assistant = text_fixed.split(\"<|im_start|>assistant\")[1] if \"<|im_start|>assistant\" in text_fixed else \"N/A\"\n",
    "print(f\"<|im_start|>assistant{fixed_assistant}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Has <think> tags?\")\n",
    "print(f\"  BROKEN: {'<think>' in text_broken}\")\n",
    "print(f\"  FIXED:  {'<think>' in text_fixed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test with Real Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data not found at: ../src/training/rest/outputs/rest/filtered/filtered.json\n",
      "Please update the path to your filtered.json file\n"
     ]
    }
   ],
   "source": [
    "# Load a sample from your actual training data\n",
    "train_data_path = \"../src/training/rest/outputs/rest/filtered/filtered.json\"  # Adjust path as needed\n",
    "\n",
    "if os.path.exists(train_data_path):\n",
    "    with open(train_data_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    print(f\"Loaded {len(data)} training samples\")\n",
    "    print(\"\\nFirst sample:\")\n",
    "    print(json.dumps(data[0], indent=2)[:1000])\n",
    "else:\n",
    "    print(f\"Training data not found at: {train_data_path}\")\n",
    "    print(\"Please update the path to your filtered.json file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process a real sample with the FIXED approach\n",
    "if os.path.exists(train_data_path) and len(data) > 0:\n",
    "    sample = data[0]\n",
    "    question = sample.get(\"question\", \"\").replace(\"<sound>\", \"\").strip()\n",
    "    response = sample.get(\"response\", \"\")\n",
    "    \n",
    "    print(\"Question:\", question[:100], \"...\" if len(question) > 100 else \"\")\n",
    "    print(\"\\nResponse (first 500 chars):\")\n",
    "    print(response[:500])\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    \n",
    "    # Check if response has thinking\n",
    "    has_think = \"<think>\" in response\n",
    "    print(f\"Response has <think> tags: {has_think}\")\n",
    "    \n",
    "    if has_think:\n",
    "        # Simulate the FIXED training approach\n",
    "        conversation_without_assistant = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": [{\"type\": \"text\", \"text\": \"You are a helpful assistant that analyzes audio carefully. Think step by step before giving your final answer.\"}],\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"audio\", \"audio\": \"/path/to/audio.wav\"},\n",
    "                    {\"type\": \"text\", \"text\": question},\n",
    "                ],\n",
    "            },\n",
    "        ]\n",
    "        \n",
    "        text = processor.apply_chat_template(\n",
    "            conversation_without_assistant, tokenize=False, add_generation_prompt=True\n",
    "        )\n",
    "        text = text + response + \"<|im_end|>\\n\"\n",
    "        \n",
    "        print(\"\\nFIXED training text (with thinking preserved):\")\n",
    "        print(\"=\" * 60)\n",
    "        print(text)\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"\\n<think> preserved in final text: {'<think>' in text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Tokenization Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs around the thinking section:\n",
      "============================================================\n",
      "\n",
      "Around position 23:\n",
      "    [21]  77091 = 'assistant'\n",
      "    [22]    198 = '\\n'\n",
      ">>> [23] 151667 = '<think>'\n",
      "    [24]    198 = '\\n'\n",
      "    [25]     40 = 'I'\n",
      "\n",
      "Around position 30:\n",
      "    [28]  11958 = ' bird'\n",
      "    [29]    624 = '.\\n'\n",
      ">>> [30] 151668 = '</think>'\n",
      "    [31]    271 = '\\n\\n'\n",
      "    [32]  11692 = 'ANS'\n"
     ]
    }
   ],
   "source": [
    "# Check that the tokens are correct\n",
    "response = \"<think>\\nI hear a bird.\\n</think>\\n\\nANSWER: Bird\"\n",
    "\n",
    "conversation_without_assistant = [\n",
    "    {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": \"You are helpful.\"}]},\n",
    "    {\"role\": \"user\", \"content\": [\n",
    "        {\"type\": \"audio\", \"audio\": \"/path/to/audio.wav\"},\n",
    "        {\"type\": \"text\", \"text\": \"What sound?\"},\n",
    "    ]},\n",
    "]\n",
    "\n",
    "text = processor.apply_chat_template(\n",
    "    conversation_without_assistant, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "text = text + response + \"<|im_end|>\\n\"\n",
    "\n",
    "# Tokenize\n",
    "tokens = processor.tokenizer.encode(text, add_special_tokens=False)\n",
    "\n",
    "print(\"Token IDs around the thinking section:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Find and show tokens around <think>\n",
    "decoded_tokens = [processor.tokenizer.decode([t]) for t in tokens]\n",
    "for i, (tok_id, tok_str) in enumerate(zip(tokens, decoded_tokens)):\n",
    "    if 'think' in tok_str.lower() or 'answer' in tok_str.lower() or tok_str.strip() in ['<', '>', '/', 'ANSWER']:\n",
    "        # Show context around these tokens\n",
    "        start = max(0, i - 2)\n",
    "        end = min(len(tokens), i + 3)\n",
    "        print(f\"\\nAround position {i}:\")\n",
    "        for j in range(start, end):\n",
    "            marker = \">>>\" if j == i else \"   \"\n",
    "            print(f\"{marker} [{j}] {tokens[j]:6d} = {repr(decoded_tokens[j])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Why the Bug Happens (Template Logic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The template sets `ns.last_query_index` based on:\n",
      "\n",
      "    {%- if message.role == \"user\" and message.content is string ... %}\n",
      "        {%- set ns.last_query_index = index %}\n",
      "    {%- endif %}\n",
      "\n",
      "KEY: \"message.content is string\"\n",
      "\n",
      "For multimodal content, we use ARRAY format:\n",
      "    \"content\": [{\"type\": \"audio\", ...}, {\"type\": \"text\", ...}]\n",
      "\n",
      "This is NOT a string, so the condition fails!\n",
      "\n",
      "Then later, thinking is only added if:\n",
      "    {%- if loop.index0 > ns.last_query_index %}\n",
      "\n",
      "But since ns.last_query_index wasn't updated, this condition is FALSE\n",
      "for the assistant message, and <think> tags are stripped.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The chat template has this logic:\n",
    "template_logic = '''\n",
    "The template sets `ns.last_query_index` based on:\n",
    "\n",
    "    {%- if message.role == \"user\" and message.content is string ... %}\n",
    "        {%- set ns.last_query_index = index %}\n",
    "    {%- endif %}\n",
    "\n",
    "KEY: \"message.content is string\"\n",
    "\n",
    "For multimodal content, we use ARRAY format:\n",
    "    \"content\": [{\"type\": \"audio\", ...}, {\"type\": \"text\", ...}]\n",
    "\n",
    "This is NOT a string, so the condition fails!\n",
    "\n",
    "Then later, thinking is only added if:\n",
    "    {%- if loop.index0 > ns.last_query_index %}\n",
    "\n",
    "But since ns.last_query_index wasn't updated, this condition is FALSE\n",
    "for the assistant message, and <think> tags are stripped.\n",
    "'''\n",
    "\n",
    "print(template_logic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STRING content (works):\n",
      "  'What sound?' is string: True\n",
      "\n",
      "ARRAY content (breaks thinking):\n",
      "  [{'type': 'audio'...}] is string: False\n",
      "\n",
      "This is why multimodal breaks the template's thinking logic!\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate the string vs array difference\n",
    "print(\"STRING content (works):\")\n",
    "print(f\"  'What sound?' is string: {isinstance('What sound?', str)}\")\n",
    "\n",
    "print(\"\\nARRAY content (breaks thinking):\")\n",
    "array_content = [{\"type\": \"audio\", \"audio\": \"x\"}, {\"type\": \"text\", \"text\": \"What?\"}]\n",
    "print(f\"  [{{'type': 'audio'...}}] is string: {isinstance(array_content, str)}\")\n",
    "\n",
    "print(\"\\nThis is why multimodal breaks the template's thinking logic!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### The Bug\n",
    "- Qwen3-Omni's chat template strips `<think>` tags when user content is an array (multimodal)\n",
    "- This is because the template logic checks `message.content is string`\n",
    "\n",
    "### The Fix\n",
    "1. Apply chat template only to system + user messages (`add_generation_prompt=True`)\n",
    "2. Manually append the assistant response with `<think>` tags preserved\n",
    "\n",
    "### Verification\n",
    "- BROKEN: `<|im_start|>assistant\\nANSWER: Bird<|im_end|>`\n",
    "- FIXED: `<|im_start|>assistant\\n<think>\\n...\\n</think>\\n\\nANSWER: Bird<|im_end|>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flux_finetuning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
